# Evaluación 1 de Arquitectura de Computadoras
Alumna: Daisy Gonzalez Lita                   Número de control:22620056
## Cuestionario Avanzado sobre Arquitectura de Computadoras

    **Tema 1: Evolución de la Arquitectura de Computadoras**

1. **¿Qué limitaciones de la arquitectura de Von Neumann llevaron al desarrollo de arquitecturas alternativas como Harvard, segmentada y de multiprocesamiento?** limitaciones de longitud de las instrucciones por el bus de datos, limitaciones en velocidad, cuellos de botella y complejidad de programación.
2. **¿Cómo la arquitectura Harvard aborda las limitaciones de rendimiento de la arquitectura de Von Neumann?** La arquitectura de Harvard utliza dos buses separados para trasferir datos entre la memoria de datos y la ALU, además tiene la ventaja de permitir el acceso simultáneo a la memoria de programa y a la memoria de datos.
3. **Explique la diferencia entre la segmentación de instrucciones y la segmentación de datos en una arquitectura segmentada.**  En la segmentación de instrucciones permite ejecutar varias etapas de instrucciones simultáneamente en un solo procesador. Esto aumenta el rendimiento del procesador sin necesidad de acelerar todas sus unidades, en cambio l segmentación de datos, es un método que aumenta el rendimiento de algunos sistemas electrónicos digitales. Se basa en leer instrucciones de la memoria mientras se ejecutan otras en otros segmentos de la secuencia. 
4. **Compare y contraste las arquitecturas de multiprocesamiento simétrico (SMP) y asimétrico (AMP).**  Ambas arquitecturas son modelos son conceptuales para diseñar computadoras digitales, también se basa en la idea de dividir el proceso de ejecución de instrucciones en varias unidades de procesamiento, cada una realizada por un procesador diferente. Multiprocesamiento simétrico (SMP):  En esta arquitectura, los procesadores comparten la memoria y los dispositivos de E/S, y una única imagen del sistema operativo (SO) se ejecuta en todos ellos. El SO se encarga de repartir las tareas y de gestionar los recursos. Esta arquitectura es ideal para aplicaciones que requieren una potencia de procesamiento uniforme. Por otro lado el Multiprocesamiento asimétrico (AMP): En esta arquitectura, cada procesador se encarga de tareas específicas. 

    **Tema 2:  Componentes de un Sistema de Computación**

5. **¿Cómo la Ley de Moore ha influenciado la evolución de los microprocesadores?**  La Ley de Moore predice que el número de transistores por dispositivo se duplicará cada dos años.
6. **Describa las funciones principales de cada unidad dentro de la CPU: Unidad de Control (UC), Unidad Aritmético-Lógica (ALU) y Unidad de Coma Flotante (FPU).**  Unidad de Control (UC): Es un dispositivo del sistema de cómputo que dirige y controla el funcionamiento de los demás componentes. La UC se encarga de administrar los recursos del ordenador y de controlar el flujo de datos a través del procesador. 
Unidad Aritmético-Lógica (ALU) :Es la parte del computador donde se realizan las operaciones aritméticas y lógicas sobre los datos. La ALU utiliza el bus de datos para comunicarse con otras unidades. 
Unidad de Coma Flotante (FPU) :Es un componente de la CPU que se especializa en las operaciones de punto flotante. La FPU realiza operaciones aritméticas entre dos valores, pero lo hace para números en representación de coma flotante, que es más complicada que la representación de complemento a dos usada en una ALU. 
7. **Explique la jerarquía de memoria y su impacto en el rendimiento del sistema.** La jerarquía de memoria es una organización de los dispositivos de almacenamiento de una computadora, basada en su velocidad, tamaño, costo y funciones. El objetivo es reducir el tiempo de acceso y acelerar las operaciones. 
Los niveles de la jerarquía de memoria son: Registro, Memoria caché, Memoria primaria (RAM), Disco duro, Cintas magnéticas. El impacto de su rendimiento podría ser el causante de que tan rápido responda el equipo a las instrucciones dadas por los usuarios.
8. **Compare y contraste las arquitecturas CISC y RISC.**  	El microprocesador es complejo en estructura y potente en función, por lo que es fácil realizar las funciones especiales.	El microprocesador tiene una estructura simple, instrucciones regulares, rendimiento fácil de entender, fácil de aprender y usar.
9. **¿Cuáles son las ventajas y desventajas de integrar una GPU en la CPU?**  Las ventajas de integrar una GPU en la CPU son la eficiencia energética, costos más bajos, menor espacio físico, compartición de recursos, mientras que las desventajas son rendimiento gráfico especializado, compartición de la memoria RAM, escalabilidad reducida y limitación de en los núcleos y la arquitectura.

    **Tema 3: Memoria y Almacenamiento**

10. **Diferencia entre memoria volátil y no volátil, proporcionando ejemplos de cada tipo.**  La diferencia entre memoria volátil y memoria no volátil radica en la capacidad de retener datos cuando no hay suministro eléctrico, memoria volatil es un tipo de memoria que pierde su contenido cuando se interrumpe la alimentación eléctrica, ejemplo RAM (Memoria de Acceso Aleatorio), por otro lado memoria no volátil es un tipo de memoria que retiene los datos almacenados incluso sin suministro eléctrico, ejemplo ROM (Memoria de Solo Lectura).
11. **Explique el rol de la memoria caché y sus diferentes niveles (L1, L2, L3) en la optimización del rendimiento.**   El rol de memoria caché es que almacena los datos frecuentemente accedidos, redice la brecha de velocidad y optimiza el uso del procesador, nivel de caché de nivel 1 (L1), almacena datos e instrucciones más utilizados de manera inmediata, nivel de caché de nivel 2 (L2)  almacena datos menos frecuentes o que no caben en la caché L1 y el nivel de caché de nivel 3 (L3) actúa como un "reservorio" para los datos que no caben en L1 y L2, optimizando la colaboración entre núcleos en tareas multihilo.
12. **¿Cómo se gestionan las interrupciones en un sistema de computación?** Es un proceso donde inicia con la detencción de señal y la envía al procesador, después hace  un reconocimiento, luego inicia una la suspención en la pila, posteriormente hace la tranferencia de control, y por último hace la ejecución del ISR.

    **Tema 4: Entrada/Salida y Buses**

13. **Describa la diferencia entre entrada/salida programada y acceso directo a memoria (DMA).**  La diferencia entre Entrada/Salida Programada (PIO) y Acceso Directo a Memoria (DMA) radica en cómo se gestionan las transferencias de datos entre dispositivos de entrada/salida y la memoria principal del sistema. Estos métodos tienen impactos significativos en la eficiencia y en el uso de los recursos del procesador.
14. **¿Cuáles son los tres tipos principales de buses en un sistema de computación y sus funciones?** 1. Bus de datos su función es que transporta los datos reales entre el procesador, la memoria principal y los dispositivos de entrada/salida.  2. Bus de Dirección su función radica en transportar las direcciones de la memoria o de los dispositivos donde se deben leer o escribir datos.   3.Bus de control transporta las señales de control que coordinan y gestionan las operaciones entte diferentes componentes del sistema.
15. **Explique el concepto de "cuello de botella" en el contexto de la arquitectura de Von Neumann y cómo las arquitecturas alternativas buscan mitigarlo.** Un cuello de botella en la arquitectura de Von Neumann es una limitación en el rendimiento del sistema computacional causada por el diseño de esta arquitectura, que utiliza un único bus compartido para transferir datos e instrucciones entre la CPU y la memoria principal, por ello se crearon alternativas como la arquitectura de Harvard la cual tiene dos buses separados, uno para datos y otro para instrucciones.

    **Tema 5:  Programación y Software**

16. **Explique la diferencia entre un compilador y un intérprete.** Un compilador es un programa que traduce el código fuente completo (escrito en un lenguaje de alto nivel) a un lenguaje máquina o código intermedio antes de que se ejecute mientras que un intérprete traduce el código fuente línea por línea y lo ejecuta inmediatamente, sin generar un archivo ejecutable independiente.
17. **¿Qué es un lenguaje ensamblador y cómo se relaciona con el lenguaje máquina?**  Un lenguaje ensamblador es un lenguaje de programación de bajo nivel que sirve como una representación simbólica y más entendible para las personas del lenguaje máquina. Está diseñado para interactuar directamente con el hardware del sistema, utilizando instrucciones específicas para la arquitectura del procesador.
   18. **Describa el proceso de "ligado" (linking) en la creación de un programa ejecutable.**  El proceso de ligado (linking) es una etapa en la creación de un programa ejecutable. Este proceso combina y organiza los diferentes componentes del código del programa, como archivos objeto, bibliotecas y otros recursos, en un único archivo ejecutable que puede ser cargado y ejecutado por el sistema operativo. Las fases principales son: 1.Compilación previa, 2.Ligado (Linking) se encarga de procesar estos archivos y resolver las referencias externas para generara un archivo  ejecutable completo.
19. **¿Qué son las llamadas al sistema y cómo se utilizan en la programación?**  Son funciones que un programa de aplicación utiliza para solicitar servicios del sistema operativo, como acceso a archivos, comunicación, gestión de procesos, o uso de dispositivos de hardware, su modo de ejecución es: Una llamada al sistema implica un cambio del modo de usuario (user mode) al modo núcleo (kernel mode), donde el sistema operativo tiene privilegios completos.

    **Tema 6:  Rendimiento y Optimización**

20. **¿Qué factores se consideran al medir el rendimiento de un sistema de computación?**  Velocidad de procesamiento, capacidad de memoria, redimiento de entrada y salida, rendimiento multitarea, consumo de energía, medición de latencia, rendimiento gráfico, y relación costo beneficio.
21. **Explique la diferencia entre localidad espacial y temporal en el contexto de acceso a memoria.**  La localidad espacial y la localidad temporal son patrones de acceso que los sistemas de memoria explotan para optimizar el rendimiento. Mientras que la espacial se enfoca en datos cercanos, la temporal prioriza los datos reutilizados.
22. **¿Cómo el paralelismo a nivel de instrucción (ILP) y el paralelismo a nivel de datos (DLP) contribuyen a mejorar el rendimiento?**  El paralelismo a nivel de instrucción (ILP) mejora el rendimiento  ejecutando múltiples instrucciones simultánneamente, uso de unidades funcionales independientes, y optimiza la memoria caché, por otro lado la el paralelismo a nivel de datos (DLP) mejora el redimiento con el procesamiento en paralelo de datos, utiliza unidades de SIMD, vectorización de operaciones. ILP mejora el rendimiento mediante la ejecución paralela de instrucciones dentro de un solo hilo, maximizando la utilización de las unidades funcionales del procesador.
DLP, por su parte, acelera el procesamiento al realizar la misma operación en múltiples datos en paralelo, utilizando unidades de procesamiento especializadas como SIMD y GPUs.
23. **¿Qué son los cuellos de botella en el rendimiento y cómo se identifican y resuelven?** Un cuello de botella en el rendimiento de un sistema de computación se refiere a un componente o parte del sistema que limita la velocidad general del procesamiento de datos, ya que actúa como un punto de congestión o restricción. Este cuello de botella ralentiza el flujo de trabajo en el sistema, ya que no permite que otros componentes trabajen al ritmo óptimo. Los cuellos de botella pueden ocurrir en cualquier parte del sistema, como la CPU, la memoria, el almacenamiento o la red, y su impacto puede ser significativo si no se identifican y resuelven. Para identificar los cuellos de botella, es necesario observar el comportamiento de los componentes del sistema bajo diversas condiciones y realizar análisis de rendimiento. Algunos métodos comunes para identificarlos incluyen: Monitoreo de utilización de recursos, Pruebas de Benchmarking y perfilado del código. El cuello de botella en la CPU se resuelven optimizando el código y paralelización, es decir, dividir el trabajo en múltiples hilos o procesos para aprovechar los múltiples núcleos del CPU. Cuello de botella en la memoria se soluciona optimizando la memoria caché y realizando una ampliación de la memoria Ram.

    **Tema 7: Clasificación de Multiprocesadores**

24. **Explique la taxonomía de Flynn para clasificar arquitecturas paralelas.** La taxonomía de Flynn es un sistema de clasificación de arquitecturas paralelas basado en la cantidad de flujos de instrucciones y datos que un procesador puede manejar de manera simultánea. Fue propuesta por Michael J. Flynn en 1966 y ha sido fundamental para entender cómo organizar los procesadores para aprovechar el paralelismo.  Las cuatro categorías de la taxonomía de Flynn: 1. SISD (Single Instruction stream, Single Data stream), 2. SIMD (Single Instruction stream, Multiple Data streams), 3. MISD (Multiple Instruction streams, Single Data stream) y 4. MIMD (Multiple Instruction streams, Multiple Data streams).
25. **Describa las características principales de cada categoría en la taxonomía de Flynn: SISD, SIMD, MISD, MIMD.**  1. SISD (Single Instruction stream, Single Data stream) En esta arquitectura, el sistema ejecuta una sola instrucción a la vez y opera sobre un solo flujo de datos. Es una arquitectura secuencial, sin paralelismo, como la de las computadoras tradicionales. Ventajas: Simplicidad y facilidad de diseño.           Desventajas: No puede aprovechar el paralelismo en las tareas; es limitada en términos de rendimiento para trabajos de alto procesamiento.          2. SIMD (Single Instruction stream, Multiple Data streams) En esta arquitectura, el procesador ejecuta una única instrucción que opera sobre múltiples flujos de datos de manera simultánea. Este tipo de arquitectura es común en operaciones vectoriales o en operaciones que se pueden paralelizar de forma masiva, como en las Unidades de Procesamiento Gráfico (GPU).
Ventajas: Alta eficiencia para tareas como el procesamiento de imágenes, videos, simulaciones científicas y criptografía, donde la misma operación se repite en múltiples datos.
Desventajas: El paralelismo está limitado a operaciones que pueden ejecutarse de forma idéntica en múltiples datos, por lo que no es adecuado para todo tipo de aplicaciones.                                                                                                                        3. MISD (Multiple Instruction streams, Single Data stream) En esta arquitectura, múltiples instrucciones operan sobre un solo flujo de datos. Aunque en la práctica es rara, esta categoría describe sistemas donde varios procesadores realizan diferentes operaciones en el mismo dato.         Ventajas: Puede ser útil para aplicaciones que requieren alta confiabilidad y redundancia, como en sistemas de control de vuelo o de alta seguridad.
Desventajas: Esta arquitectura no se utiliza comúnmente en la práctica, ya que la implementación y los beneficios en rendimiento son limitados. La redundancia y la sobrecarga pueden disminuir la eficiencia. 
4. MIMD (Multiple Instruction streams, Multiple Data streams) En esta arquitectura, múltiples instrucciones se ejecutan simultáneamente sobre múltiples flujos de datos. Es la forma más general y flexible de paralelismo, ya que permite ejecutar diferentes instrucciones de forma independiente en diferentes conjuntos de datos.                                                                 
Ventajas: Es la más versátil y escalable, ya que puede ejecutar una variedad de tareas en paralelo y se adapta a una amplia gama de aplicaciones, como simulaciones científicas, procesamiento de grandes bases de datos, aprendizaje automático y más.
Desventajas: Requiere una compleja coordinación entre los procesadores y la gestión de los datos. Además, puede haber problemas de consistencia de datos y sincronización entre los procesadores.

26. **Diferencie entre multiprocesadores fuertemente acoplados y débilmente acoplados.** La diferencia entre multiprocesadores fuertemente acoplados y débilmente acoplados radica en cómo se gestionan y se comunican los procesadores dentro del sistema. En los sistemas de multiprocesadores fuertemente acoplados, todos los procesadores comparten una memoria común, es decir memoria compartida, coherencia de memoria y alta interdependencia, en cambio en los sistemas de multiprocesadores débilmente acoplados, los procesadores tienen memoria privada (local), es decir, memoria distribuida, comunicación más lenta, menor interdependecia.

    **Tema 8:  Tendencias en la Arquitectura de Computadoras**

27. **¿Cómo el crecimiento del procesamiento en la nube está impactando la arquitectura de los centros de datos?**  El crecimiento del procesamiento en la nube ha tenido un impacto muy grande en la arquitectura de los centros de datos, debido a la necesidad de manejar grandes volúmenes de datos, ofrecer escalabilidad, y garantizar alta disponibilidad y eficiencia. Algunos puntos importantes a resaltar son la virtualización y la optimización de energía y eficiencia
28. **¿Cuáles son las ventajas y desventajas de las arquitecturas de sistemas en chip (SoC)?**  Ventajas de las Arquitecturas SoC: Reducción de tamaños y costos, eficiencia energética, mejora el rendimiento por vatio, facilidad de diseño y producción, conectividad optimizada y reducción de espacio físico. Desventajas: Limitación en la personalización, complejidad del diseño, problemas de actualización, rendimiento limitado para tareas específicas, y dependencia del proveedor.
29. **¿Cómo la inteligencia artificial (IA) está influyendo en la evolución de la arquitectura de computadoras?** La inteligencia artificial (IA) está teniendo un impacto muy fuerte en la evolución de la arquitectura de computadoras, tanto en el diseño de hardware como en la optimización de procesos, por ejemplo la miniaturización y mayor densidad de transistores.

**Pregunta general:**

30. **¿Cómo los avances en la tecnología de semiconductores han impulsado la evolución de la arquitectura de computadoras?** La tecnología de los semiconductores han sido parte importante para impulsar la evolución de la arquitectura de computadoras, permitiendo mejoras en el rendimiento, la eficiencia energética y la miniaturización de los dispositivos. 
